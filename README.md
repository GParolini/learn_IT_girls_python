# learn_IT_girls_python

######Preliminary remarks######
The python code in this repository has been produced as part of my participation in the Learn IT, Girl! initiative (https://www.learnitgirl.com) during spring 2019. You can find a short abstract of the project I am developing below.
The code has been written to examine a bibliographic dataset produced as part of my research on the history of agricultural meteorology during the first half of the twentieth century. My historical research is sponsored by the Deutsche Forschungsgemeinschaft (DFG) (Project No. 321660352).
I sincerely thank my mentor, Dr Laura Fernández Gallardo, for the support received during the Learn IT, Girl! initiative.
Berlin, April 2019

######Structure of the repository######
There are four subfolders: "1_data" for the data to be examined; "2_code_scripts" for the python code; "3_printouts" for the printouts of information extracted from the data (e.g.list of all the authors in the dataset, list of the journal titles etc.); "4_plots" for the graphs generated from the data". All the printouts and plots are generated by the code in "2_code_scripts".
The folder "2_code_scripts" is structured in four scripts: main.py is the main script (you have to run it to clean the data and generate printouts and plots), data_methods.py contains a few methods for the initial cleaning of the data, utilities.py contains methods for printing printouts/plots in the right folder and support methods for generating the language count list and aggregate data for generating the association between journals and categories; print_methods.py contains methods for generating the printouts in "3_printouts"; plot_methods.py contains methods for generating the plots in "4_plots". 

######What can you do with this code######
Data methods: load data, generate a list of the columns names in the loaded dataset, delete the columns with high number of Nans, drop columns by hand, print the cleaned data in a csv
Print methods: generate a list of the itemtypes and their count; generate an alphabetic list of titles for the different itemtypes; count the number of articles published in each journal, generate a list of all the authors (co-authors splitted); generate a list of the 'first autors' (co-authors maintained together); generate the count of publications for each author.
Plot methods: histogram of the publication per each year; histogram and pie plot of the publications for each language (data in the pie plot are aggregate); pie plot of the journals distributed according to category (the correspondence list journal-category is in the data folder); scatter plot of the journal categories (for all categories and for all years; for all categories and a restricted timeframe); line plot of the journal categories (for all categories and for all years; for the main categories and all years)

######Potential for code reuse######
The dataset analysed has been exported from a Zotero library (https://www.zotero.org). It should not be difficult to re-use the code for analysing different datasets produced with Zotero. Pay only attention to the naming conventions I used in the code (e.g.data are read from the file "bibliography_data.csv").  

######Project description######
Title: Digital History with Python: Data Analysis and Machine Learning with Bibliographic References
Abstract: The project will explore how data science methods and machine learning can contribute to my historical research by examining a large bibliographic data set of publications on agricultural meteorology that appeared in the years 1900-1950. The data set is being built as part of my research project on the history of agricultural meteorology in the first half of the twentieth century (https://agriculturalmeteorology.wordpress.com). It currently contains over 3.300 entries in several languages, ranging from English to Japanese, and belonging to multiple disciplines such as meteorology, agriculture, botany, geography. The data are collected using the reference management software Zotero and can be easily exported for analysis as csv/JSON files. During the project I will learn: a) the basics of the Python programming language (through self-study of Z. Shaw’s ‘Learn Python the Hard Way’); b) the use of tools based on Python (e.g. Pandas and Matplotlib) to visualise and analyse my bibliographic data set and discover trends in the data (e.g. whether there was an increase in the number of publications over time, who were the most prolific authors, which were the journals that published more contributions on agricultural meteorology); c) how to apply machine learning methods to the data set publications that have an abstract available and test whether classification algorithms can reliably attribute the publications to different knowledge domains (e.g. meteorology journals vs agricultural journals vs multi-discipline journals such as ‘Nature’ and ‘Science’) by using keywords, word frequency, etc.By applying data science, I will be able to extract information from my bibliographic data set otherwise not available through traditional historical methods. This, I believe, will give me deeper insights on how agricultural meteorology developed as an interdisciplinary research field in the first half of the twentieth century.
